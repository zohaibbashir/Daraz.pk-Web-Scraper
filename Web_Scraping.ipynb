{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "D71oyiUlUaMD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "from lxml import html\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import re\n",
    "\n",
    "def removeChar(s,x):\n",
    "    return s.replace(x, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tY2uyDKhUaMQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sdzv1oQ_UaMT",
    "outputId": "e2145788-610d-4ca6-c4bf-25d68ca43069"
   },
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "user=input(\"Enter a Product Name:\")\n",
    "st=\"\"\n",
    "for i in user.split():\n",
    "    st+=i + \"+\"\n",
    "st = st[:-1]\n",
    "url=f'https://www.daraz.pk/catalog/?q={st}&_keyori=ss&from=input&spm=a2a0e.home.search.go.35e3493779rCiu'\n",
    "driver = webdriver.Chrome('chromedriver')\n",
    "#final_url=\"https://www.daraz.pk/catalog/?q=mobile+phone&_keyori=ss&from=input&spm=a2a0e.home.search.go.35e3493779rCiu\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "html = driver.page_source\n",
    "\n",
    "parsed_html = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "containers = parsed_html.find_all(\"div\", {\"class\" : \"gridItem--Yd0sa\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Normally how text is extracted via Web Scraping. Not very hard to do\n",
    "2. To count the review(s) I had to go into the .css file of the website that can be accessed via (inspect element) or (page source).Go into the Elements tab and choose the star icon via tha inspect icon or using Ctrl+Shift+C. In the Elements tab below is another bar. In that bar there will be a tab for Styles. Click on that and you will see the .css file for the Stars/review. In the Styles tab, click on desktop.css or whatever is written on the top-left corner for the star information. You will be moved to the tab Sources. From there use filter or Ctrl+f to find .star to get the values of the stars\n",
    "3. Using Inspect Element I found the tag and applied normal Web Scraping Techniques\n",
    "4. Extracted the text and applied normal Web Scraping Techniques\n",
    "5. Extracted the text and used Regular Expression to get the name of the Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuFMpVQNUaMX"
   },
   "outputs": [],
   "source": [
    "names=[]\n",
    "prices=[]\n",
    "ratings=[]\n",
    "reviews=[]\n",
    "discount=[]\n",
    "discount_rate=[]\n",
    "darazMall=[]\n",
    "freeDelivery=[]\n",
    "country=[]\n",
    "#\"\"\"\n",
    "for i in range(0,(len(containers))):\n",
    "    first_product = containers[i]\n",
    "    \"\"\"\n",
    "    [1]\n",
    "    \"\"\"\n",
    "    pro_names=first_product.find('div', class_ = 'info--ifj7U')\n",
    "    product=pro_names.a['title']\n",
    "    #print(product,\"\\n\\n\\n\\n\")\n",
    "    names.append(product)\n",
    "    pro_prices = first_product.find('span', class_ = 'currency--GVKjl')\n",
    "    pro_prices = pro_prices.text\n",
    "    pro_prices=pro_prices[4:]\n",
    "  \n",
    "    \n",
    "    prices.append(str(pro_prices))\n",
    "    rat= first_product.find('div', class_ = 'rating--ZI3Ol rate--DCc4j')\n",
    "    #print(rat,\"\\n\\n\\n\\n\")\n",
    "    s1=str(rat)\n",
    "    \"\"\"\n",
    "    [2]\n",
    "    \"\"\"\n",
    "    \n",
    "    #star-0--WgmCt\n",
    "    #star-1--Do7NZ\n",
    "    #star-2--fBIsH\n",
    "    #star-3--zmTQe\n",
    "    #star-4--hM0en\n",
    "    #star-5--hXNSC\n",
    "    #star-6--ezGMb\n",
    "    #star-7--UNNG4\n",
    "    #star-8--lQLaV\n",
    "    #star-9--yMyuX\n",
    "    #star-icon--k88DV\n",
    "    #star-10--UQtQk\n",
    "    \n",
    "    \n",
    "    #pro_names=first_product.find('div', class_ = 'c16H9d')\n",
    "    #print(pro_names)\n",
    "    \n",
    "    count0=s1.count(\"star-icon--k88DV star-0--WgmCt\")\n",
    "    count0_1=s1.count(\"star-icon--k88DV star-1--Do7NZ\")\n",
    "    count0_25=s1.count(\"star-icon--k88DV star-2--fBIsH\")\n",
    "    \n",
    "    count0_3=s1.count(\"star-icon--k88DV star-3--zmTQe\")\n",
    "    count0_4=s1.count(\"star-icon--k88DV star-4--hM0en\")\n",
    "    count0_5=s1.count(\"star-icon--k88DV star-5--hXNSC\")\n",
    "    \n",
    "    count0_6=s1.count(\"star-icon--k88DV star-6--ezGMb\")\n",
    "    count0_75=s1.count(\"star-icon--k88DV star-7--UNNG4\")\n",
    "    count0_8=s1.count(\"star-icon--k88DV star-8--lQLaV\")\n",
    "    \n",
    "    count0_9=s1.count(\"star-icon--k88DV star-9--yMyuX\")\n",
    "    count1=s1.count(\"star-icon--k88DV star-10--UQtQk\")\n",
    "    \n",
    "    \n",
    "    count0_1*=0.1\n",
    "    count0_25*=0.25\n",
    "    count0_3*=0.3\n",
    "    \n",
    "    count0_4*=0.4\n",
    "    count0_5*=0.5\n",
    "    count0_6*=0.6\n",
    "    \n",
    "    count0_8*=0.8\n",
    "    count0_75*=0.75\n",
    "    count0_9*=0.9\n",
    "    \n",
    "    totalcount=  count0_1 + count0_25 + count0_3 + count0_4 + count0_5+ count0_6+ count0_75 + count0_8 + count0_9 + count1\n",
    "    ratings.append(totalcount)\n",
    "    #print(totalcount,\"\\n\\n\\n\")\n",
    "    \n",
    "    \"\"\"\n",
    "    [3]\n",
    "    \"\"\"\n",
    "    \n",
    "    mall=first_product.find('i', class_ = 'ic-dynamic-badge ic-dynamic-badge-lazMall ic-dynamic-group-1')\n",
    "    if(mall):\n",
    "        darazMall.append(\"Yes\")\n",
    "    else:\n",
    "        darazMall.append(\"No\")\n",
    "    \n",
    "    free=first_product.find('i', class_ = 'ic-dynamic-badge ic-dynamic-badge-freeShipping ic-dynamic-group-2')\n",
    "    if(free):\n",
    "        freeDelivery.append(\"Yes\")\n",
    "    else:\n",
    "        freeDelivery.append(\"No\")\n",
    "    \n",
    "    \n",
    "    discnt = first_product.find('del', class_ = 'currency--GVKjl')\n",
    "    if(discnt):\n",
    "        discnt = discnt.text\n",
    "        #print(discnt,\"\\n\\n\\n\")\n",
    "        discnt=discnt[4:]\n",
    "        discount.append(discnt)\n",
    "    else:\n",
    "        discount.append(pro_prices)\n",
    "    \n",
    "    \"\"\"\n",
    "    [4]\n",
    "    \"\"\"\n",
    "    dis_rate= first_product.find('span', class_ = 'discount--HADrg')\n",
    "    if(dis_rate):\n",
    "        dis_rate = dis_rate.text\n",
    "        dis_rate=removeChar(dis_rate,'-')\n",
    "        #print(dis_rate,\"\\n\\n\\n\")\n",
    "        discount_rate.append(dis_rate)\n",
    "    else:\n",
    "        discount_rate.append(\"0%\")\n",
    "    \n",
    "    \"\"\"\n",
    "    [5]\n",
    "    \"\"\"\n",
    "    count_names=first_product.find('div', class_ = 'rateAndLoc--XWchq')\n",
    "    count_names=count_names.span.text\n",
    "    count_names=re.findall(r'[^(\\d) ]+',count_names)\n",
    "    count_names=' '.join(map(str,count_names))\n",
    "    #print(count_names,\"\\n\\n\\n\")\n",
    "    if(count_names):\n",
    "        country.append(count_names)\n",
    "    else:\n",
    "        country.append(\"Not Mentioned\")\n",
    "    \n",
    "    review_name=first_product.find('span', class_ = 'rating__review--ygkUy')\n",
    "    if(review_name):\n",
    "        review=review_name.text\n",
    "        review=removeChar(review,'(')\n",
    "        review=removeChar(review,')')\n",
    "        reviews.append(review)\n",
    "    else:\n",
    "        reviews.append(\"0\")\n",
    "    \n",
    "    \n",
    "    \n",
    "#for i in range(0,(len(containers))):\n",
    " #   print(names[i],\"\\t\\t\",prices[i],\"\\t\",ratings[i],\"\\t\",darazMall[i],\"\\t\",freeDelivery[i],\"\\t\",discount[i],\"\\t\",discount_rate[i],\"\\t\",country[i],\"\\t\",reviews[i])   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GryYW6D8UaMb",
    "outputId": "d1e7339b-6aab-4368-aee9-3526dd6e86bf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tot=parsed_html.find('div', class_ = 'tips--QRnmZ')\n",
    "total=tot.text\n",
    "#print(total)\n",
    "s2=\"\"\n",
    "for i in range(len(total)):\n",
    "    if(total[i]==' '):\n",
    "        break\n",
    "    s2+=total[i]\n",
    "avgprice=0.0\n",
    "for i in range(0,(len(containers))):\n",
    "    prices[i]=removeChar(prices[i],',')\n",
    "    avgprice+=float(prices[i])\n",
    "avgprice=avgprice/len(containers)\n",
    "avgrev=0.0\n",
    "for i in range(0,(len(containers))):\n",
    "    avgrev+=float(reviews[i])\n",
    "avgrev=avgrev/len(containers)\n",
    "avgrat=0.0\n",
    "for i in range(0,(len(containers))):\n",
    "    avgrat+=float(ratings[i])\n",
    "avgrat=avgrat/len(containers)\n",
    "print(f'Total Products of {user} are:',s2)\n",
    "print(\"Average Price: \",avgprice)\n",
    "print(\"Average Reviews: \",format(avgrev,'.2f'))\n",
    "print(\"Average Ratings: \",format(avgrat,'.2f'))\n",
    "#print(avgprice/len(containers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khjB3PiPUaMd",
    "outputId": "ddb72f6b-7f11-45e3-e439-6f96abdeb388",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(names, darazMall,discount,prices,discount_rate,ratings,reviews,country,freeDelivery)),\n",
    "                  columns =['Name', 'Daraz Mall','Original Price',' Discounted Price','Discount Rate','Rating','Reviews','Seller Country','Free Delivery'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62S2mjS6UaMf"
   },
   "outputs": [],
   "source": [
    "df.to_csv(r'result.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6uic4DQUaMg"
   },
   "source": [
    "# Placing all of the code in 1 cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k4Fb8uHvUaMj",
    "outputId": "110f6638-b88a-4366-dbdd-af5bafe175a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a Product Name:Sonic\n",
      "Enter upto how many Pages you want to receive Information from:10\n",
      "\n",
      "Total Products of Sonic are: 5237\n",
      "Average Price of Products on Page 1:  4107.775\n",
      "Average Reviews of Products on Page 1:  10.82\n",
      "Average Ratings of Products on Page 1:  1.58\n",
      "\n",
      "\n",
      "\n",
      "Average Price of Products on Page 2:  2025.25\n",
      "Average Reviews of Products on Page 2:  15.20\n",
      "Average Ratings of Products on Page 2:  3.26\n",
      "\n",
      "\n",
      "\n",
      "Average Price of Products on Page 3:  971.825\n",
      "Average Reviews of Products on Page 3:  28.27\n",
      "Average Ratings of Products on Page 3:  2.94\n",
      "\n",
      "\n",
      "\n",
      "Average Price of Products on Page 4:  1386.0\n",
      "Average Reviews of Products on Page 4:  37.55\n",
      "Average Ratings of Products on Page 4:  3.70\n",
      "\n",
      "\n",
      "\n",
      "Average Price of Products on Page 5:  916.575\n",
      "Average Reviews of Products on Page 5:  2.30\n",
      "Average Ratings of Products on Page 5:  2.29\n",
      "\n",
      "\n",
      "\n",
      "Average Price of Products on Page 6:  1153.55\n",
      "Average Reviews of Products on Page 6:  0.93\n",
      "Average Ratings of Products on Page 6:  1.65\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "user=input(\"Enter a Product Name:\")\n",
    "choices=int(input(\"Enter upto how many Pages you want to receive Information from:\"))\n",
    "st=\"\"\n",
    "page=1\n",
    "for i in user.split():\n",
    "        st+=i + \"+\"\n",
    "st = st[:-1]\n",
    "for pages in range(1,choices+1):\n",
    "    \n",
    "    \n",
    "    #     https://www.daraz.pk/catalog/?q=Andriod+phones&_keyori=ss&from=input&page=2&spm=a2a0e.home.search.go.35e34937JY020J\n",
    "    url=f'https://www.daraz.pk/catalog/?q={st}&_keyori=ss&from=input&page={page}&spm=a2a0e.home.search.go.35e3493779rCiu'\n",
    "    driver = webdriver.Chrome('chromedriver')\n",
    "    #final_url=\"https://www.daraz.pk/catalog/?q=mobile+phone&_keyori=ss&from=input&spm=a2a0e.home.search.go.35e3493779rCiu\"\n",
    "    driver.get(url)\n",
    "    #time.sleep(5)\n",
    "    \n",
    "\n",
    "    html = driver.page_source\n",
    "    \n",
    "\n",
    "    parsed_html = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    containers = parsed_html.find_all(\"div\", {\"class\" : \"gridItem--Yd0sa\"})\n",
    "\n",
    "\n",
    "\n",
    "    names=[]\n",
    "    prices=[]\n",
    "    ratings=[]\n",
    "    reviews=[]\n",
    "    discount=[]\n",
    "    discount_rate=[]\n",
    "    darazMall=[]\n",
    "    freeDelivery=[]\n",
    "    country=[]\n",
    "    #\"\"\"\n",
    "    for i in range(0,(len(containers))):\n",
    "        first_product = containers[i]\n",
    "\n",
    "        pro_names=first_product.find('div', class_ = 'info--ifj7U')\n",
    "        product=pro_names.a['title']\n",
    "        #print(product,\"\\n\\n\\n\\n\")\n",
    "        names.append(product)\n",
    "        pro_prices = first_product.find('span', class_ = 'currency--GVKjl')\n",
    "        pro_prices = pro_prices.text\n",
    "        pro_prices=pro_prices[4:]\n",
    "\n",
    "\n",
    "        prices.append(str(pro_prices))\n",
    "        rat= first_product.find('div', class_ = 'rating--ZI3Ol rate--DCc4j')\n",
    "        #print(rat,\"\\n\\n\\n\\n\")\n",
    "        s1=str(rat)\n",
    "\n",
    "\n",
    "        #star-0--WgmCt\n",
    "        #star-1--Do7NZ\n",
    "        #star-2--fBIsH\n",
    "        #star-3--zmTQe\n",
    "        #star-4--hM0en\n",
    "        #star-5--hXNSC\n",
    "        #star-6--ezGMb\n",
    "        #star-7--UNNG4\n",
    "        #star-8--lQLaV\n",
    "        #star-9--yMyuX\n",
    "        #star-icon--k88DV\n",
    "        #star-10--UQtQk\n",
    "\n",
    "\n",
    "        #pro_names=first_product.find('div', class_ = 'c16H9d')\n",
    "        #print(pro_names)\n",
    "\n",
    "        count0=s1.count(\"star-icon--k88DV star-0--WgmCt\")\n",
    "        count0_1=s1.count(\"star-icon--k88DV star-1--Do7NZ\")\n",
    "        count0_25=s1.count(\"star-icon--k88DV star-2--fBIsH\")\n",
    "\n",
    "        count0_3=s1.count(\"star-icon--k88DV star-3--zmTQe\")\n",
    "        count0_4=s1.count(\"star-icon--k88DV star-4--hM0en\")\n",
    "        count0_5=s1.count(\"star-icon--k88DV star-5--hXNSC\")\n",
    "\n",
    "        count0_6=s1.count(\"star-icon--k88DV star-6--ezGMb\")\n",
    "        count0_75=s1.count(\"star-icon--k88DV star-7--UNNG4\")\n",
    "        count0_8=s1.count(\"star-icon--k88DV star-8--lQLaV\")\n",
    "\n",
    "        count0_9=s1.count(\"star-icon--k88DV star-9--yMyuX\")\n",
    "        count1=s1.count(\"star-icon--k88DV star-10--UQtQk\")\n",
    "\n",
    "\n",
    "        count0_1*=0.1\n",
    "        count0_25*=0.25\n",
    "        count0_3*=0.3\n",
    "\n",
    "        count0_4*=0.4\n",
    "        count0_5*=0.5\n",
    "        count0_6*=0.6\n",
    "\n",
    "        count0_8*=0.8\n",
    "        count0_75*=0.75\n",
    "        count0_9*=0.9\n",
    "\n",
    "        totalcount=  count0_1 + count0_25 + count0_3 + count0_4 + count0_5+ count0_6+ count0_75 + count0_8 + count0_9 + count1\n",
    "        ratings.append(totalcount)\n",
    "        #print(totalcount,\"\\n\\n\\n\")\n",
    "\n",
    "        mall=first_product.find('i', class_ = 'ic-dynamic-badge ic-dynamic-badge-lazMall ic-dynamic-group-1')\n",
    "        if(mall):\n",
    "            darazMall.append(\"Yes\")\n",
    "        else:\n",
    "            darazMall.append(\"No\")\n",
    "\n",
    "        free=first_product.find('i', class_ = 'ic-dynamic-badge ic-dynamic-badge-freeShipping ic-dynamic-group-2')\n",
    "        if(free):\n",
    "            freeDelivery.append(\"Yes\")\n",
    "        else:\n",
    "            freeDelivery.append(\"No\")\n",
    "\n",
    "\n",
    "        discnt = first_product.find('del', class_ = 'currency--GVKjl')\n",
    "        if(discnt):\n",
    "            discnt = discnt.text\n",
    "            #print(discnt,\"\\n\\n\\n\")\n",
    "            discnt=discnt[4:]\n",
    "            discount.append(discnt)\n",
    "        else:\n",
    "            discount.append(pro_prices)\n",
    "\n",
    "        dis_rate= first_product.find('span', class_ = 'discount--HADrg')\n",
    "        if(dis_rate):\n",
    "            dis_rate = dis_rate.text\n",
    "            dis_rate=removeChar(dis_rate,'-')\n",
    "            #print(dis_rate,\"\\n\\n\\n\")\n",
    "            discount_rate.append(dis_rate)\n",
    "        else:\n",
    "            discount_rate.append(\"0%\")\n",
    "\n",
    "\n",
    "        count_names=first_product.find('div', class_ = 'rateAndLoc--XWchq')\n",
    "        count_names=count_names.span.text\n",
    "        count_names=re.findall(r'[^(\\d) ]+',count_names)\n",
    "        count_names=' '.join(map(str,count_names))\n",
    "        #print(count_names,\"\\n\\n\\n\")\n",
    "        if(count_names):\n",
    "            country.append(count_names)\n",
    "        else:\n",
    "            country.append(\"Not Mentioned\")\n",
    "\n",
    "        review_name=first_product.find('span', class_ = 'rating__review--ygkUy')\n",
    "        if(review_name):\n",
    "            review=review_name.text\n",
    "            review=removeChar(review,'(')\n",
    "            review=removeChar(review,')')\n",
    "            reviews.append(review)\n",
    "        else:\n",
    "            reviews.append(\"0\")\n",
    "\n",
    "\n",
    "\n",
    "    #for i in range(0,(len(containers))):\n",
    "     #   print(names[i],\"\\t\\t\",prices[i],\"\\t\",ratings[i],\"\\t\",darazMall[i],\"\\t\",freeDelivery[i],\"\\t\",discount[i],\"\\t\",discount_rate[i],\"\\t\",country[i],\"\\t\",reviews[i])   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    tot=parsed_html.find('div', class_ = 'tips--QRnmZ')\n",
    "    total=tot.text\n",
    "    #print(total)\n",
    "    s2=\"\"\n",
    "    for i in range(len(total)):\n",
    "        if(total[i]==' '):\n",
    "            break\n",
    "        s2+=total[i]\n",
    "    avgprice=0.0\n",
    "    for i in range(0,(len(containers))):\n",
    "        prices[i]=removeChar(prices[i],',')\n",
    "        avgprice+=float(prices[i])\n",
    "    avgprice=avgprice/len(containers)\n",
    "    avgrev=0.0\n",
    "    for i in range(0,(len(containers))):\n",
    "        avgrev+=float(reviews[i])\n",
    "    avgrev=avgrev/len(containers)\n",
    "    avgrat=0.0\n",
    "    for i in range(0,(len(containers))):\n",
    "        avgrat+=float(ratings[i])\n",
    "    avgrat=avgrat/len(containers)\n",
    "    \n",
    "\n",
    "    if(page==1):\n",
    "        df = pd.DataFrame(list(zip(names, darazMall,discount,prices,discount_rate,ratings,reviews,country,freeDelivery)), columns =['Name', 'Daraz Mall','Original Price',' Discounted Price','Discount Rate','Rating','Reviews','Seller Country','Free Delivery'])\n",
    "        \n",
    "        print(f'\\nTotal Products of {user} are:',s2)\n",
    "    else:\n",
    "        df2 = pd.DataFrame(list(zip(names, darazMall,discount,prices,discount_rate,ratings,reviews,country,freeDelivery)), columns =['Name', 'Daraz Mall','Original Price',' Discounted Price','Discount Rate','Rating','Reviews','Seller Country','Free Delivery'])\n",
    "        df = pd.concat([df, df2], ignore_index = True, axis = 0)\n",
    "       \n",
    "        \n",
    "    print(f'Average Price of Products on Page {page}\\t: ',avgprice)\n",
    "    print(f'Average Reviews of Products on Page {page}: ',format(avgrev,'.2f'))\n",
    "    print(f'Average Ratings of Products on Page {page}: ',format(avgrat,'.2f'))\n",
    "    driver.close()\n",
    "    page+=1\n",
    "    print(\"\\n\\n\")\n",
    "df.to_csv(r'result.csv', index = False)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Zohaib_i191669_Lab_Assignment (Web Scraping).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
